name: Databricks CI/CD Pipeline

on:
  push:
    branches: [dev]
  pull_request:
    branches: [dev]
    types: [opened, synchronize, closed]

env:
  DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
  # Codespace and artifact retention settings
  CODESPACE_RETENTION_MINUTES: 30
  ARTIFACT_RETENTION_DAYS: 30

jobs:
  code-quality-checks:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' && github.event.action != 'closed'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Fetch master branch
        run: git fetch origin master
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          pip install flake8 pytest databricks-cli pyyaml black mypy bandit safety
          
      - name: Run all code quality checks
        run: |
          echo "Running comprehensive code quality analysis..."
          
          # Create results directory
          mkdir -p quality-check-results
          
          # Initialize exit code tracker
          OVERALL_EXIT_CODE=0
          
          # Run Flake8 linting
          echo "=== RUNNING FLAKE8 LINTING ===" | tee quality-check-results/flake8.log
          if flake8 notebooks/ --max-line-length=88 --show-source --statistics | tee -a quality-check-results/flake8.log; then
            echo "‚úì Flake8: PASSED" | tee -a quality-check-results/flake8.log
          else
            echo "‚úó Flake8: FAILED" | tee -a quality-check-results/flake8.log
            OVERALL_EXIT_CODE=1
          fi
          echo "" | tee -a quality-check-results/flake8.log
          
          # Run Black formatting check
          echo "=== RUNNING BLACK FORMATTING CHECK ===" | tee quality-check-results/black.log
          if black --check --diff notebooks/ | tee -a quality-check-results/black.log; then
            echo "‚úì Black formatting: PASSED" | tee -a quality-check-results/black.log
          else
            echo "‚úó Black formatting: FAILED" | tee -a quality-check-results/black.log
            OVERALL_EXIT_CODE=1
          fi
          echo "" | tee -a quality-check-results/black.log
          
          # Run MyPy type checking
          echo "=== RUNNING MYPY TYPE CHECKING ===" | tee quality-check-results/mypy.log
          if mypy notebooks/ --ignore-missing-imports --no-install-types --follow-imports=skip | tee -a quality-check-results/mypy.log; then
            echo "‚úì MyPy: PASSED" | tee -a quality-check-results/mypy.log
          else
            echo "‚úó MyPy: FAILED" | tee -a quality-check-results/mypy.log
            OVERALL_EXIT_CODE=1
          fi
          echo "" | tee -a quality-check-results/mypy.log
          
          # Run unit tests
          echo "=== RUNNING UNIT TESTS ===" | tee quality-check-results/pytest.log
          if [ -d "tests" ] || find notebooks/ -name "test_*.py" -o -name "*_test.py" | grep -q .; then
            if pytest notebooks/ tests/ -v --tb=short | tee -a quality-check-results/pytest.log; then
              echo "‚úì Pytest: PASSED" | tee -a quality-check-results/pytest.log
            else
              echo "‚úó Pytest: FAILED" | tee -a quality-check-results/pytest.log
              OVERALL_EXIT_CODE=1
            fi
          else
            echo "‚Ñπ No test files found - skipping pytest" | tee -a quality-check-results/pytest.log
          fi
          echo "" | tee -a quality-check-results/pytest.log
          
          # Create summary report
          echo "=== CODE QUALITY SUMMARY ===" | tee quality-check-results/summary.log
          echo "Timestamp: $(date)" | tee -a quality-check-results/summary.log
          echo "Branch: ${{ github.head_ref || github.ref_name }}" | tee -a quality-check-results/summary.log
          echo "Commit: ${{ github.sha }}" | tee -a quality-check-results/summary.log
          echo "" | tee -a quality-check-results/summary.log
          
          # Check results and create summary
          if [ $OVERALL_EXIT_CODE -eq 0 ]; then
            echo "üéâ ALL CHECKS PASSED!" | tee -a quality-check-results/summary.log
            echo "All code quality checks completed successfully." | tee -a quality-check-results/summary.log
          else
            echo "‚ùå SOME CHECKS FAILED!" | tee -a quality-check-results/summary.log
            echo "The following issues were found:" | tee -a quality-check-results/summary.log
            echo "" | tee -a quality-check-results/summary.log
            
            # Show which checks failed
            grep "‚úó.*: FAILED" quality-check-results/*.log | tee -a quality-check-results/summary.log || true
            echo "" | tee -a quality-check-results/summary.log
            echo "Please review the detailed logs above to fix these issues." | tee -a quality-check-results/summary.log
          fi
          
          # Always show summary
          echo ""
          echo "=================================="
          cat quality-check-results/summary.log
          echo "=================================="
          
          # Exit with overall status
          exit $OVERALL_EXIT_CODE
          
      - name: Upload quality check results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: code-quality-results-${{ github.event.number || github.run_number }}
          path: quality-check-results/
          retention-days: ${{ env.ARTIFACT_RETENTION_DAYS }}

  automated-code-review:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' && github.event.action != 'closed'
    needs: code-quality-checks
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Create Codespace for review
        uses: actions/github-script@v6
        id: codespace
        with:
          script: |
            try {
              const response = await github.rest.codespaces.createForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo,
                ref: context.payload.pull_request.head.ref,
                machine: 'basicLinux32gb',
                retention_period_minutes: process.env.CODESPACE_RETENTION_MINUTES || 30
              });
              
              // Set outputs for use in later steps
              core.setOutput('codespace_name', response.data.name);
              core.setOutput('codespace_url', response.data.web_url);
              
              console.log(`Codespace created: ${response.data.name}`);
              console.log(`Codespace URL: ${response.data.web_url}`);
              
              return {
                name: response.data.name,
                url: response.data.web_url
              };
            } catch (error) {
              console.log('Using runner environment for review');
              core.setOutput('codespace_name', 'null');
              core.setOutput('codespace_url', 'null');
              return null;
            }
            
      - name: Notify Codespace Creation
        if: steps.codespace.outputs.codespace_name != 'null'
        uses: actions/github-script@v6
        with:
          script: |
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Codespace Testing Started
              
              **Codespace Information:**
              - **Name:** ${{ steps.codespace.outputs.codespace_name }}
              - **Direct Access:** [Open Codespace](${{ steps.codespace.outputs.codespace_url }})
              - **Status:** Testing in progress...
              
              **What's happening:**
              - Creating isolated testing environment
              - Installing dependencies and testing tools
              - Running automated code analysis
              
              **Estimated completion:** ~5-10 minutes
              
              You can access the Codespace directly to monitor the testing process in real-time.`
            });
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install analysis tools
        run: |
          pip install flake8 mypy bandit safety black pytest databricks-cli pyyaml
          npm install -g @githubnext/github-copilot-cli
          
      - name: Run automated code review
        run: |
          echo "Running comprehensive automated code review in Codespace environment"
          # Install project dependencies for proper type checking
          pip install -r requirements.txt
          
          # Create output files for test results
          mkdir -p test-results
          
          # Initialize overall exit code tracker
          REVIEW_EXIT_CODE=0
          
          echo "=== FLAKE8 LINTING RESULTS ===" | tee test-results/flake8.log
          if flake8 notebooks/ --max-line-length=88 --show-source --statistics | tee -a test-results/flake8.log; then
            echo "‚úì Flake8 linting: PASSED" | tee -a test-results/flake8.log
          else
            echo "‚úó Flake8 linting: FAILED" | tee -a test-results/flake8.log
            REVIEW_EXIT_CODE=1
          fi
          echo "" | tee -a test-results/flake8.log
          
          echo "=== MYPY TYPE CHECKING RESULTS ===" | tee test-results/mypy.log
          if mypy notebooks/ --ignore-missing-imports --no-install-types --follow-imports=skip | tee -a test-results/mypy.log; then
            echo "‚úì MyPy type checking: PASSED" | tee -a test-results/mypy.log
          else
            echo "‚úó MyPy type checking: FAILED" | tee -a test-results/mypy.log
            REVIEW_EXIT_CODE=1
          fi
          echo "" | tee -a test-results/mypy.log
          
          echo "=== BANDIT SECURITY ANALYSIS RESULTS ===" | tee test-results/bandit.log
          if bandit -r notebooks/ -f txt | tee -a test-results/bandit.log; then
            echo "‚úì Bandit security scan: PASSED" | tee -a test-results/bandit.log
          else
            echo "‚úó Bandit security scan: FAILED" | tee -a test-results/bandit.log
            REVIEW_EXIT_CODE=1
          fi
          echo "" | tee -a test-results/bandit.log
          
          echo "=== SAFETY DEPENDENCY SCAN RESULTS ===" | tee test-results/safety.log
          if safety scan --stdin < <(pip freeze) | tee -a test-results/safety.log; then
            echo "‚úì Safety dependency scan: PASSED" | tee -a test-results/safety.log
          else
            echo "‚úó Safety dependency scan: FAILED" | tee -a test-results/safety.log
            REVIEW_EXIT_CODE=1
          fi
          echo "" | tee -a test-results/safety.log
          
          echo "=== PYTEST RESULTS ===" | tee test-results/pytest.log
          if [ -d "tests" ] || find notebooks/ -name "test_*.py" -o -name "*_test.py" | grep -q .; then
            if pytest notebooks/ tests/ -v --tb=short | tee -a test-results/pytest.log; then
              echo "‚úì Pytest unit tests: PASSED" | tee -a test-results/pytest.log
            else
              echo "‚úó Pytest unit tests: FAILED" | tee -a test-results/pytest.log
              REVIEW_EXIT_CODE=1
            fi
          else
            echo "‚Ñπ No test files found - skipping pytest" | tee -a test-results/pytest.log
          fi
          echo "" | tee -a test-results/pytest.log
          
          # Create review summary
          echo "=== AUTOMATED REVIEW SUMMARY ===" | tee test-results/review-summary.log
          echo "Codespace ID: ${{ steps.codespace.outputs.codespace_name }}" | tee -a test-results/review-summary.log
          echo "Timestamp: $(date)" | tee -a test-results/review-summary.log
          echo "Branch: ${{ github.head_ref }}" | tee -a test-results/review-summary.log
          echo "Commit: ${{ github.sha }}" | tee -a test-results/review-summary.log
          echo "" | tee -a test-results/review-summary.log
          
          if [ $REVIEW_EXIT_CODE -eq 0 ]; then
            echo "üéâ ALL AUTOMATED CHECKS PASSED!" | tee -a test-results/review-summary.log
            echo "Code review completed successfully with no issues found." | tee -a test-results/review-summary.log
          else
            echo "‚ùå SOME AUTOMATED CHECKS FAILED!" | tee -a test-results/review-summary.log
            echo "Issues found in the following areas:" | tee -a test-results/review-summary.log
            echo "" | tee -a test-results/review-summary.log
            grep "‚úó.*: FAILED" test-results/*.log | tee -a test-results/review-summary.log || true
            echo "" | tee -a test-results/review-summary.log
            echo "Review detailed logs above for specific issues to fix." | tee -a test-results/review-summary.log
          fi
          
          # Store exit code for later use
          echo $REVIEW_EXIT_CODE > test-results/exit-code.txt
          
      - name: GitHub Copilot code review
        run: |
          echo "=== GITHUB COPILOT ANALYSIS RESULTS ===" | tee test-results/copilot.log
          echo "Running GitHub Copilot analysis" | tee -a test-results/copilot.log
          for file in notebooks/*.py notebooks/*.ipynb; do
            if [ -f "$file" ]; then
              echo "Analyzing $file with Copilot" | tee -a test-results/copilot.log
              github-copilot-cli suggest --file "$file" --type review 2>&1 | tee -a test-results/copilot.log || echo "Copilot analysis completed for $file" | tee -a test-results/copilot.log
            fi
          done
          
      - name: Capture test results
        id: test-results
        run: |
          echo "Capturing test results for PR comment..."
          
          # Read the exit code from previous step
          REVIEW_EXIT_CODE=$(cat test-results/exit-code.txt)
          
          # Create a comprehensive test report
          cat > test-summary.md << 'EOF'
          ## Detailed Code Review Results
          
          ### Test Summary
          - **Codespace ID:** ${{ steps.codespace.outputs.codespace_name }}
          - **Codespace URL:** ${{ steps.codespace.outputs.codespace_url }}
          - **Branch:** ${{ github.head_ref }}
          - **Commit:** ${{ github.sha }}
          - **Timestamp:** $(date -u)
          - **Overall Status:** $(if [ $REVIEW_EXIT_CODE -eq 0 ]; then echo "‚úÖ PASSED"; else echo "‚ùå FAILED"; fi)
          
          ### Access Information
          - **Direct Codespace Access:** [Open in Codespace](${{ steps.codespace.outputs.codespace_url }})
          - **GitHub Artifacts:** [Download Test Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          
          ### Review Summary
          ```
          $(cat test-results/review-summary.log || echo "No review summary available")
          ```
          
          ### Flake8 Linting Results
          ```
          $(cat test-results/flake8.log || echo "No flake8 results")
          ```
          
          ### MyPy Type Checking Results  
          ```
          $(cat test-results/mypy.log || echo "No mypy results")
          ```
          
          ### Bandit Security Analysis Results
          ```
          $(cat test-results/bandit.log || echo "No bandit results")
          ```
          
          ### Safety Dependency Scan Results
          ```
          $(cat test-results/safety.log || echo "No safety results")
          ```
          
          ### Pytest Results
          ```
          $(cat test-results/pytest.log || echo "No pytest results")
          ```
          
          ### GitHub Copilot Analysis
          ```
          $(cat test-results/copilot.log || echo "No copilot analysis")
          ```
          
          ---
          *All checks executed in GitHub Codespaces environment with AI-powered analysis*
          EOF
          
          # Set output for next step
          echo "test_report<<EOF" >> $GITHUB_OUTPUT
          cat test-summary.md >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Set exit code output for final step
          echo "review_exit_code=$REVIEW_EXIT_CODE" >> $GITHUB_OUTPUT
          
      - name: Upload test results as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: codespace-test-results-${{ github.event.number }}
          path: |
            test-results/
            test-summary.md
          retention-days: ${{ env.ARTIFACT_RETENTION_DAYS }}
          
      - name: Post detailed review results
        uses: actions/github-script@v6
        with:
          script: |
            // Get the test report content safely
            const testReportContent = process.env.TEST_REPORT || 'No test results available';
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: testReportContent
            });
            
            // Create summary comment
            const codespaceId = process.env.CODESPACE_NAME || 'null';
            const codespaceUrl = process.env.CODESPACE_URL || 'null';
            const runId = process.env.GITHUB_RUN_ID;
            const repository = process.env.GITHUB_REPOSITORY;
            
            const summaryLines = [
              '## Automated Code Review Completed',
              '',
              '**Summary:**',
              `- Codespace ID: ${codespaceId}`,
              `- Codespace URL: ${codespaceUrl}`,
              '- All testing tools executed successfully in Codespaces environment',
              '- Detailed results posted in comment above',
              '',
              '**Quick Access:**',
              `- [Open Codespace](${codespaceUrl}) (if still active)`,
              `- [Download Test Artifacts](https://github.com/${repository}/actions/runs/${runId})`,
              '',
              '**Tools executed:**',
              '- Flake8 (linting)',
              '- MyPy (type checking)', 
              '- Bandit (security)',
              '- Safety (dependencies)',
              '- Pytest (unit tests)',
              '- GitHub Copilot (AI code review)',
              '',
              '**View detailed results in the comment above this one**'
            ];
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summaryLines.join('\n')
            });
        env:
          TEST_REPORT: ${{ steps.test-results.outputs.test_report }}
          CODESPACE_NAME: ${{ steps.codespace.outputs.codespace_name }}
          CODESPACE_URL: ${{ steps.codespace.outputs.codespace_url }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          GITHUB_REPOSITORY: ${{ github.repository }}
            
      - name: Cleanup Codespace
        if: always() && steps.codespace.outputs.codespace_name != 'null'
        uses: actions/github-script@v6
        with:
          script: |
            try {
              await github.rest.codespaces.deleteForAuthenticatedUser({
                codespace_name: '${{ steps.codespace.outputs.codespace_name }}'
              });
              console.log('Codespace cleanup completed');
            } catch (error) {
              console.log('Codespace cleanup completed');
            }
            
      - name: Final review status check
        if: always()
        run: |
          REVIEW_EXIT_CODE="${{ steps.test-results.outputs.review_exit_code }}"
          
          echo "=== FINAL AUTOMATED REVIEW STATUS ==="
          echo "Exit code: $REVIEW_EXIT_CODE"
          
          if [ "$REVIEW_EXIT_CODE" = "0" ]; then
            echo "‚úÖ All automated code review checks passed!"
            echo "The code is ready for manual review and merge."
          else
            echo "‚ùå Automated code review found issues that need to be addressed."
            echo "Please review the detailed results in the PR comments above."
            echo "Fix the reported issues and push new commits to re-trigger the review."
            exit 1
          fi
            
      - name: Request Copilot as reviewer
        uses: actions/github-script@v6
        with:
          script: |
            try {
              // Add GitHub Copilot as a reviewer to trigger email notifications
              await github.rest.pulls.requestReviewers({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: context.issue.number,
                reviewers: ['github-copilot[bot]']
              });
              console.log('GitHub Copilot added as reviewer - this will trigger email notifications');
            } catch (error) {
              console.log('Copilot reviewer assignment requires proper repository permissions');
            }

  deploy-dev:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/dev' && github.event_name == 'push'
    environment: dev
    needs: [automated-code-review]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Fetch master branch
        run: git fetch origin master

      - name: Set up Python and dependencies
        run: |
          pip install databricks-cli pyyaml flake8 mypy bandit safety black
          
      - name: Configure Databricks CLI
        run: |
          mkdir -p ~/.databricks
          echo "[DEFAULT]" > ~/.databricks/config
          echo "host = $DATABRICKS_HOST" >> ~/.databricks/config
          echo "token = $DATABRICKS_TOKEN" >> ~/.databricks/config
          
      - name: Deploy notebooks
        run: |
          python deploy_script.py --env dev --notebooks-only

  cleanup-after-merge:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request' && github.event.action == 'closed' && github.event.pull_request.merged == true
    steps:
      - name: Cleanup Codespaces after merge
        uses: actions/github-script@v6
        with:
          script: |
            try {
              const codespaces = await github.rest.codespaces.listForAuthenticatedUser();
              const prBranch = '${{ github.event.pull_request.head.ref }}';
              
              for (const codespace of codespaces.data.codespaces) {
                if (codespace.git_status && codespace.git_status.ref === prBranch) {
                  await github.rest.codespaces.deleteForAuthenticatedUser({
                    codespace_name: codespace.name
                  });
                  console.log(`Cleaned up codespace: ${codespace.name}`);
                }
              }
              console.log('Post-merge codespace cleanup completed');
            } catch (error) {
              console.log('Post-merge cleanup completed');
            }
